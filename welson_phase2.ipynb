{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86be8b3a421eedd8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a0fb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420461f7dd5acd1e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "# Get Font 1 templates ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1040ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder containing your JPEG images\n",
    "folder_path = 'digits/font_3/'\n",
    "# Create lists to store original and processed images\n",
    "original_images = []\n",
    "processed_images = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aaea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.jpg'):\n",
    "        print(filename)\n",
    "        # Read the image in grayscale\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        image = cv2.imread(image_path, 0)\n",
    "        # Threshold the image to create a binary mask\n",
    "        _, thresh = cv2.threshold(image, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Get the height and width of the image\n",
    "        height, width = image.shape[:2]\n",
    "\n",
    "        # Create a mask to fill border-connected regions\n",
    "        mask = np.zeros((height + 2, width + 2), dtype=np.uint8)\n",
    "        for contour in contours:\n",
    "            # Get bounding box coordinates\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "            # If contour touches the border of the image, fill it with white in the mask\n",
    "            if x == 0 or y == 0 or x + w == width or y + h == height:\n",
    "                cv2.drawContours(mask, [contour], 0, 255, -1)  # Fill contour in the mask\n",
    "\n",
    "        # Crop the mask to match the size of the input image\n",
    "        mask = mask[1:-1, 1:-1]\n",
    "\n",
    "        # Apply the mask to the original image to turn border-connected pixels black\n",
    "        result = image.copy()\n",
    "        result[mask == 255] = 0  # Set pixels to black where mask is white\n",
    "\n",
    "        # Append original and processed images to lists\n",
    "        original_images.append(image)\n",
    "        processed_images.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784a668fbe43641c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T14:05:29.760485600Z",
     "start_time": "2023-12-27T14:05:29.615960Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to make border pixels black\n",
    "def make_border_black(image_array):\n",
    "    height, width = image_array.shape\n",
    "    image_array[0, :] = 0  # Top border\n",
    "    image_array[height - 1, :] = 0  # Bottom border\n",
    "    image_array[:, 0] = 0  # Left border\n",
    "    image_array[:, width - 1] = 0  # Right border\n",
    "    return image_array\n",
    "\n",
    "# Display the original image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(original_images[0], cmap='gray')\n",
    "plt.axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdc8f7380f931b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T14:05:40.036012300Z",
     "start_time": "2023-12-27T14:05:36.272455300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show original vs processed images\n",
    "num_images = len(processed_images)\n",
    "\n",
    "plt.figure(figsize=(14, 7 * num_images))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(num_images, 2, i * 2 + 1)\n",
    "    plt.imshow(original_images[i], cmap='gray')\n",
    "    plt.title(f'Original Image {i+1}')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(num_images, 2, i * 2 + 2)\n",
    "    plt.imshow(processed_images[i], cmap='gray')\n",
    "    plt.title(f'Processed Image {i+1}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e47060b839727d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T14:05:47.168431700Z",
     "start_time": "2023-12-27T14:05:47.115754100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_and_draw_longest_lines(image):\n",
    "    edges = cv2.Canny(image, 50, 300)\n",
    "    lines = cv2.HoughLines(edges, 1, np.pi / 180, threshold=40)\n",
    "\n",
    "    longest_vertical_line = None\n",
    "    longest_horizontal_line = None\n",
    "    max_vertical_length = 0\n",
    "    max_horizontal_length = 0\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            rho, theta = line[0]\n",
    "            a = np.cos(theta)\n",
    "            b = np.sin(theta)\n",
    "    \n",
    "            x0 = a * rho\n",
    "            y0 = b * rho\n",
    "            x1 = int(x0 + 1000 * (-b))\n",
    "            y1 = int(y0 + 1000 * (a))\n",
    "            x2 = int(x0 - 1000 * (-b))\n",
    "            y2 = int(y0 - 1000 * (a))\n",
    "    \n",
    "            line_length = np.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "    \n",
    "            if np.abs(b) > 0.1:  # Vertical line\n",
    "                if line_length > max_vertical_length:\n",
    "                    max_vertical_length = line_length\n",
    "                    longest_vertical_line = (x1, y1, x2, y2)\n",
    "            else:  # Horizontal line\n",
    "                if line_length > max_horizontal_length:\n",
    "                    max_horizontal_length = line_length\n",
    "                    longest_horizontal_line = (x1, y1, x2, y2)\n",
    "\n",
    "    if longest_vertical_line is not None:\n",
    "        x1, y1, x2, y2 = longest_vertical_line\n",
    "        cv2.line(image, (x1, y1), (x2, y2), (0, 0, 0), 15)\n",
    "\n",
    "    if longest_horizontal_line is not None:\n",
    "        x1, y1, x2, y2 = longest_horizontal_line\n",
    "        cv2.line(image, (x1, y1), (x2, y2), (0, 0, 0), 15)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d36e2a5107985a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T14:05:49.987916100Z",
     "start_time": "2023-12-27T14:05:49.787700200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_border_connected(image):\n",
    "    # Read the image in grayscale\n",
    "    #image = cv2.imread(image_path, 0)  # Replace with your image path\n",
    "\n",
    "    # Threshold the image to create a binary mask\n",
    "    _, thresh = cv2.threshold(image, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Get the height and width of the image\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Create a mask to fill border-connected regions\n",
    "    mask = np.zeros((height + 2, width + 2), dtype=np.uint8)\n",
    "\n",
    "    # Iterate through each contour\n",
    "    for contour in contours:\n",
    "        # Get bounding box coordinates\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        \n",
    "        # If contour touches the border of the image, fill it with white in the mask\n",
    "        if x == 0 or y == 0 or x + w == width or y + h == height:\n",
    "            cv2.drawContours(mask, [contour], 0, 255, -1)  # Fill contour in the mask\n",
    "\n",
    "    # Crop the mask to match the size of the input image\n",
    "    mask = mask[1:-1, 1:-1]\n",
    "\n",
    "    # Apply the mask to the original image to turn border-connected pixels black\n",
    "    result = image.copy()\n",
    "    result[mask == 255] = 0  # Set pixels to black where mask is white\n",
    "\n",
    "    return result\n",
    "\n",
    "# Example usage:\n",
    "image_path = 'phase1_digits/font_3/test_3/tile_1_4.jpg'  # Replace with your image path\n",
    "processed_image = remove_border_connected(cv2.imread(image_path, 0))\n",
    "\n",
    "# Display the original and processed images\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(cv2.imread(image_path, 0), cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(processed_image, cmap='gray')\n",
    "plt.title('Processed Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f345ddffa9f3bf35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T14:06:19.711899900Z",
     "start_time": "2023-12-27T14:06:19.276813800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the grayscale image\n",
    "#gray_image = cv2.imread('digits/6.jpg', 0)  # Replace 'path_to_your_grayscale_image.jpg' with the actual path\n",
    "gray_image = cv2.imread('phase1_digits/font_3/test_1/tile_2_4.jpg', 0)  # Replace 'path_to_your_grayscale_image.jpg' with the actual path\n",
    "if gray_image is None:\n",
    "    print('Image not found.')\n",
    "gray_image = make_border_black(gray_image)  \n",
    "# gray_image = find_and_draw_longest_lines(gray_image)\n",
    "inverted_gray_image = cv2.bitwise_not(gray_image)\n",
    "_, inverted_binarized_image = cv2.threshold(inverted_gray_image, 120, 255, cv2.THRESH_BINARY)  # Adjust the threshold value as needed\n",
    "NUMBER = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc5cf00",
   "metadata": {},
   "source": [
    "## Template Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685e78b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Path to the folder containing template images\n",
    "template_folder = 'digits/font_3/'\n",
    "\n",
    "# Path to the folder containing box images\n",
    "box_folder = 'phase1_digits/font_3/test_1'\n",
    "\n",
    "# Threshold for template matching\n",
    "matching_threshold = 0.5  # Adjust this threshold as needed\n",
    "\n",
    "# Create a list to store the results\n",
    "matching_results = []\n",
    "\n",
    "# Loop through each box image\n",
    "for i in range(9):\n",
    "    row_boxes = []\n",
    "    for j in range(9):\n",
    "        # Load the box image\n",
    "        box_path = os.path.join(box_folder, f'tile_{i}_{j}.jpg')\n",
    "        box_image = cv2.imread(box_path)\n",
    "        gray_box_image = cv2.cvtColor(box_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Loop through each template image\n",
    "        max_template_score = float('-inf')\n",
    "        best_template = None\n",
    "        for template_file in os.listdir(template_folder):\n",
    "            template_path = os.path.join(template_folder, template_file)\n",
    "            template = cv2.imread(template_path, 0)\n",
    "\n",
    "            # Match the template with the box image\n",
    "            result = cv2.matchTemplate(gray_box_image, template, cv2.TM_CCORR_NORMED)\n",
    "\n",
    "            # Get the maximum match score\n",
    "            _, _, _, max_loc = cv2.minMaxLoc(result)\n",
    "            max_score = result[max_loc[1], max_loc[0]]\n",
    "\n",
    "            # Update the best template if the current score is higher and above the threshold\n",
    "            if max_score > max_template_score and max_score > matching_threshold:\n",
    "                max_template_score = max_score\n",
    "                best_template = template_file\n",
    "\n",
    "        # Store the result for this box image\n",
    "        row_boxes.append((max_template_score, best_template))\n",
    "\n",
    "    # Store the results for this row of box images\n",
    "    matching_results.append(row_boxes)\n",
    "\n",
    "# Display the results\n",
    "# for i, row in enumerate(matching_results):\n",
    "#     for j, (score, template) in enumerate(row):\n",
    "#         print(f'Tile ({i},{j}): Best Match Score: {score}, Template: {template}')\n",
    "\n",
    "# # Optionally, you can visualize the results using matplotlib\n",
    "# # Note: Ensure that you have the correct file paths for the template and box images\n",
    "for i, row in enumerate(matching_results):\n",
    "    for j, (score, template) in enumerate(row):\n",
    "        box_path = os.path.join(box_folder, f'tile_{i}_{j}.jpg')\n",
    "        box_image = cv2.imread(box_path)\n",
    "\n",
    "        plt.subplot(9, 9, i * 9 + j + 1)\n",
    "        plt.imshow(cv2.cvtColor(box_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f'{score:.2f}\\n{template}', fontsize=8, color='red')\n",
    "        plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76ffd511b528b31",
   "metadata": {
    "collapsed": false
   },
   "source": [
    " # SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9adb41b26b3289",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T14:06:23.253904400Z",
     "start_time": "2023-12-27T14:06:23.185785400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def match_images_with_SIFT(gray_image, processed_images, flag):\n",
    "    sift = cv2.SIFT_create()\n",
    "    matches_count = [0] * len(processed_images)  # Assuming there are digits from 0 to 9\n",
    "\n",
    "    keypoints_sample, descriptors_sample = sift.detectAndCompute(gray_image, None)\n",
    "\n",
    "    for i, processed_image in enumerate(processed_images, 1):\n",
    "        keypoints_processed, descriptors_processed = sift.detectAndCompute(processed_image, None)\n",
    "        bf = cv2.BFMatcher()\n",
    "        matches = bf.knnMatch(descriptors_sample, descriptors_processed, k=2)\n",
    "\n",
    "        good_matches = []\n",
    "        for m, n in matches:\n",
    "            if m.distance < 0.5 * n.distance:\n",
    "                good_matches.append(m)\n",
    "        \n",
    "        matches_count[i-1] = len(good_matches)  # Update matches count at index i - 1\n",
    "        result_image = cv2.drawMatches(gray_image, keypoints_sample, processed_image, keypoints_processed, good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "        if flag:\n",
    "            \n",
    "    \n",
    "            fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "            ax[0].imshow(gray_image, cmap='gray')\n",
    "            ax[0].set_title('Sample Digit')\n",
    "            ax[0].axis('off')\n",
    "    \n",
    "            ax[1].imshow(processed_image, cmap='gray')\n",
    "            ax[1].set_title('Processed Image')\n",
    "            ax[1].axis('off')\n",
    "    \n",
    "            ax[2].imshow(result_image)\n",
    "            ax[2].set_title(f'Matches - Good Matches: {len(good_matches)}')\n",
    "            ax[2].axis('off')\n",
    "    \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        # Visualization code (commented out for returning matches_count)\n",
    "\n",
    "    return matches_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd8817e34a4988",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# ORB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09237c97d3cbab5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T14:06:25.569714200Z",
     "start_time": "2023-12-27T14:06:25.459652Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# Assuming 'gray_image' is the sample image and 'original_images' contains the processed images\n",
    "matches_array = match_images_with_SIFT(gray_image, processed_images,True)\n",
    "matches_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a8644bfa253362",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def match_images_with_ORB(gray_image, processed_images,flag):\n",
    "    orb = cv2.ORB_create()\n",
    "    matches_count = [0] * len(processed_images)  # Initialize matches_count with the length of processed_images\n",
    "\n",
    "    keypoints_sample_orb, descriptors_sample_orb = orb.detectAndCompute(gray_image, None)\n",
    "\n",
    "    for i, original_image in enumerate(processed_images):\n",
    "        keypoints_processed_orb, descriptors_processed_orb = orb.detectAndCompute(original_image, None)\n",
    "        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "        matches = bf.match(descriptors_sample_orb, descriptors_processed_orb)\n",
    "\n",
    "        matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "        good_matches_orb = []\n",
    "        for m in matches:\n",
    "            if m.distance < 40:  # Adjust this threshold as needed\n",
    "                good_matches_orb.append(m)\n",
    "\n",
    "        matches_count[i] = len(good_matches_orb)  # Update matches count at index i\n",
    "        result_image = cv2.drawMatches(gray_image, keypoints_sample_orb, original_image, keypoints_processed_orb, good_matches_orb, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "        if flag:\n",
    "            fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "            ax[0].imshow(gray_image, cmap='gray')\n",
    "            ax[0].set_title('Sample Digit')\n",
    "            ax[0].axis('off')\n",
    "    \n",
    "            ax[1].imshow(original_image, cmap='gray')\n",
    "            ax[1].set_title('Processed Image')\n",
    "            ax[1].axis('off')\n",
    "    \n",
    "            ax[2].imshow(result_image)\n",
    "            ax[2].set_title(f'Matches - Good Matches: {len(good_matches_orb)}')\n",
    "            ax[2].axis('off')\n",
    "    \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    return matches_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477411e1e45ec377",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f2d503fe47d4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T13:48:07.442152600Z",
     "start_time": "2023-12-27T13:48:05.887915600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match_images_with_ORB(gray_image, processed_images,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6046bf8b23164c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T14:11:14.022159500Z",
     "start_time": "2023-12-27T14:11:09.547438Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ROWS = 9\n",
    "COLS = 9\n",
    "\n",
    "# Define an empty 2D list to store the boxes\n",
    "sudoku_boxes = []\n",
    "template_folder = 'digits/font_1/'\n",
    "matching_threshold= 0.8\n",
    "# Iterate through each box and load it into the 2D array\n",
    "for i in range(ROWS):\n",
    "    row_boxes = []\n",
    "    for j in range(COLS):\n",
    "        # Load the box image\n",
    "        box_folder = f'phase1_digits/font_1/test_5/tile_{i}_{j}.jpg'\n",
    "        box_image = cv2.imread(box_folder, 0)\n",
    "        gray_box_image = box_image.copy()\n",
    "\n",
    "        # Loop through each template image\n",
    "        max_template_score = float('-inf')\n",
    "        best_template = None\n",
    "        template_scores = []  # Array to store the scores for each template\n",
    "        for template_file in os.listdir(template_folder):\n",
    "            template_path = os.path.join(template_folder, template_file)\n",
    "            template = cv2.imread(template_path, 0)\n",
    "\n",
    "            # Match the template with the box image\n",
    "            result = cv2.matchTemplate(gray_box_image, template, cv2.TM_CCORR_NORMED)\n",
    "\n",
    "            # Get the maximum match score\n",
    "            _, _, _, max_loc = cv2.minMaxLoc(result)\n",
    "            max_score = result[max_loc[1], max_loc[0]]\n",
    "\n",
    "            # Update the template_scores array\n",
    "            template_scores.append(max_score)\n",
    "\n",
    "            # Update the best template if the current score is higher and above the threshold\n",
    "            if max_score > max_template_score and max_score > matching_threshold:\n",
    "                max_template_score = max_score\n",
    "                best_template = template_file\n",
    "\n",
    "        # Print and store the template scores\n",
    "        \n",
    " \n",
    "        #box_image = remove_border_connected(box_image)\n",
    "        # box_image = make_border_black(box_image)\n",
    "        # make borders up to 20 pixels black  \n",
    "        box_image[:, 0:16] = 0\n",
    "        box_image[:, -16:] = 0\n",
    "        box_image[0:16, :] = 0\n",
    "        box_image[-16:, :] = 0\n",
    "        \n",
    "        \n",
    "       \n",
    "        # box_image = cv2.morphologyEx(box_image, cv2.MORPH_ERODE, np.ones((3, 3), np.uint8))\n",
    "        # # dilation\n",
    "        # box_image = cv2.morphologyEx(box_image, cv2.MORPH_DILATE, np.ones((3, 3), np.uint8))\n",
    "        plt.imshow(box_image, cmap ='gray')\n",
    "        plt.axis('on') \n",
    "        plt.show()     \n",
    "        matches_count_sift = match_images_with_SIFT(box_image, processed_images,False)\n",
    "        matches_count_orb = match_images_with_ORB(box_image, processed_images,False)\n",
    "       \n",
    "        print(f\"matches SIFT: {matches_count_sift}, matches ORB: {matches_count_orb}\" )\n",
    "        print(f\"Template Scores for tile_{i}_{j}: {[score * 10 for score in template_scores]}\")\n",
    "        average_arr = [(x + y) / 2 for x, y in zip(matches_count_sift, matches_count_orb)]\n",
    "        if all(element <= 1 for element in average_arr) or all(element ==0 for element in matches_count_orb):\n",
    "            max_index=-1\n",
    "            print (f\"tile_{i}_{j} is empty\")\n",
    "        else:\n",
    "            combined_list = [x + y + score * 10 for x, y, score in zip(matches_count_sift, matches_count_orb, template_scores)]\n",
    "            # combined_list = [x + y for x, y in zip(matches_count_sift, matches_count_orb)]\n",
    "            print (f\"combined_list: {combined_list}\")\n",
    "            max_index = combined_list.index(max(combined_list))\n",
    "            print (f\"max_index: {max_index+1}\")\n",
    "        row_boxes.append(max_index+1)\n",
    "\n",
    "    sudoku_boxes.append(row_boxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ef0841e1fae5c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T14:11:17.314031500Z",
     "start_time": "2023-12-27T14:11:17.232192300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sudoku_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca42bdf1f9f030c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def surf_matching(image_path, template_path):\n",
    "    # Read the images\n",
    "    img = cv2.imread(image_path, 0)  # Read the image as grayscale\n",
    "    template = cv2.imread(template_path, 0)  # Read the template as grayscale\n",
    "\n",
    "    # Initialize SURF detector\n",
    "    surf = cv2.xfeatures2d.SURF_create()\n",
    "\n",
    "    # Find keypoints and descriptors in the image and template\n",
    "    kp1, des1 = surf.detectAndCompute(img, None)\n",
    "    kp2, des2 = surf.detectAndCompute(template, None)\n",
    "\n",
    "    # Create a Brute-Force Matcher object\n",
    "    bf = cv2.BFMatcher()\n",
    "\n",
    "    # Match descriptors of the image and template\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    # Apply ratio test to obtain good matches\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good_matches.append(m)\n",
    "\n",
    "    # Draw matches\n",
    "    img_matches = cv2.drawMatches(img, kp1, template, kp2, good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "    return img_matches\n",
    "\n",
    "# Example usage:\n",
    "image_path = 'your_image_path.jpg'  # Replace with your image path\n",
    "template_path = 'your_template_path.jpg'  # Replace with your template path\n",
    "\n",
    "result_image = surf_matching(image_path, template_path)\n",
    "\n",
    "# Display the resulting image with matches\n",
    "cv2.imshow('SURF Matches', result_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b6b0df9ba32b38",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_2 = [[0,3,0,1,5,6,0,0,0],\n",
    "          [0,8,0,0,2,0,0,7,0],\n",
    "          [6,0,0,0,0,0,5,0,0],\n",
    "          [0,1,0,6,0,0,9,0,0],\n",
    "          [2,0,0,9,4,1,0,0,6],\n",
    "          [0,0,8,0,0,5,0,1,0],\n",
    "          [0,0,7,0,0,0,0,0,9],\n",
    "          [0,5,0,0,1,0,0,8,0],\n",
    "          [0,0,0,2,6,8,0,4,0]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
